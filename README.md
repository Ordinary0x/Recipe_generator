# ðŸ“¸ Recipe Detection & Generation System

An end-to-end AI-powered system that detects food ingredients from images and generates real, structured recipes using retrieval-augmented generation (RAG).

---

## ðŸ§  What This System Does

- Detects ingredients from a food image using **YOLOv8**
- Allows users to **confirm, edit, or add ingredients**
- Retrieves similar recipes using **ChromaDB**
- Generates **exactly 3 real recipes** using **Gemini LLM**
- Displays everything in a clean **Streamlit UI**

No fake dishes. No hallucinated garbage. Real food only.

---

## ðŸ“‚ Project Structure
```
RESCIPE_DETECTION/
â”‚
â”œâ”€â”€ app.py # FastAPI backend entry point
â”œâ”€â”€ frontend.py # Streamlit UI
â”œâ”€â”€ detect.py # YOLO ingredient detection logic
â”œâ”€â”€ yolo.py # YOLO model loader & inference wrapper
â”œâ”€â”€ generate.py # Recipe generation pipeline
â”œâ”€â”€ prompts.py # System + user prompts for LLM
â”œâ”€â”€ vectordb.py # ChromaDB creation & retrieval
â”œâ”€â”€ recipes.csv # Real recipe dataset (used for RAG)
â”œâ”€â”€ configs.py # Central configuration
â”œâ”€â”€ best.pt # Trained YOLOv8 model
```
---

## ðŸ§  System Architecture
```
Image (Upload / Camera)
â†“
YOLOv8 Ingredient Detection
â†“
User Confirmation + Edits
â†“
ChromaDB Recipe Retrieval (RAG)
â†“
Gemini LLM (Strict Prompt)
â†“
3 Structured Recipes (JSON â†’ UI)
```

---

## ðŸš€ How to Run the Project

### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate      # Linux / macOS
# venv\Scripts\activate       # Windows
```
2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

3ï¸âƒ£ Set Environment Variables
Create a .env file:
```bash
GOOGLE_API_KEY=your_gemini_api_key
```

4ï¸âƒ£ Start Backend (FastAPI)
```bash
uvicorn app:app --reload
```

Backend runs at:
```
http://127.0.0.1:8000
```
5ï¸âƒ£ Start Frontend (Streamlit)
```bash
streamlit run frontend.py
```
Frontend runs at:
```
http://localhost:8501
```
ðŸ”Œ API Endpoints
ðŸ” POST /detect

Detects ingredients from an uploaded image.

Input: Image

Response:
```bash
{
  "items": [
    { "label": "onion", "score": 0.82 },
    { "label": "tomato", "score": 0.76 }
  ],
  "meta": {
    "model": "yolov8-food",
    "threshold": 0.4
  }
}
```
ðŸ³ POST /generate

Generates recipes using RAG + Gemini LLM.

Input:
```bash
{
  "items": [
    { "label": "onion", "score": 0.9 },
    { "label": "tomato", "score": 0.8 }
  ],
  "servings": 2,
  "style": "Indian"
}
```
Response:
```bash
{
  "recipe_text": "Markdown with 3 dishes",
  "ingredients_list": [
    { "name": "onion", "quantity": "1 cup" }
  ],
  "metadata": {
    "cook_time": "30 minutes",
    "difficulty": "Easy",
    "dietary": ["Vegetarian"]
  }
}
```
ðŸŽ¯ Key Design Decisions

- YOLO only detects ingredients â€” it never decides recipes

- User confirmation is mandatory for low-confidence detections

- ChromaDB is used as a vector database for retrieval (no hype, just RAG)

- Gemini is strictly controlled via system prompts

- Exactly 3 recipes are generated â€” no more, no less

- Only real dishes, no vague or imaginary food names

âš ï¸ Known Limitations

-> Camera images may vary in exposure â†’ detection accuracy can drop

-> YOLO performance depends heavily on training data quality

-> LLM output improves as recipe dataset quality improves

ðŸ“Œ Future Improvements

-> Ingredient icons

-> Step-by-step cooking mode

-> Voice-based instructions

-> Calorie estimation
